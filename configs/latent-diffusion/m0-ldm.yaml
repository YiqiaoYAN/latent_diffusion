###first without control imgs
# model:
#   base_learning_rate: 1.0e-4
#   target: ldm.models.diffusion.ddpm.LatentDiffusion
#   params:
#     # 注意：这两个 config 都是放在 params 下面的子项
#     first_stage_config:
#       target: ldm.models.autoencoder.AutoencoderKL
#       params:
#         embed_dim: 4
#         ckpt_path: models/first_stage_models/kl-f8/model.ckpt
#         ddconfig:
#           double_z: true
#           z_channels: 4
#           resolution: 256
#           in_channels: 3
#           out_ch: 3
#           ch: 128
#           ch_mult: [1,2,4,4]
#           num_res_blocks: 2
#           attn_resolutions: []
#           dropout: 0.0
#         lossconfig:
#           target: torch.nn.Identity

#     cond_stage_config: "__is_unconditional__"

#     timesteps: 1000
#     loss_type: l2
#     image_size: 256
#     channels: 3
#     linear_start: 0.0001
#     linear_end: 0.02
#     log_every_t: 100
#     l_simple_weight: 1.0
#     conditioning_key: None
#     clip_denoised: true
#     unet_config:
#       target: ldm.modules.diffusionmodules.openaimodel.UNetModel
#       params:
#         image_size: 256
#         in_channels: 3
#         out_channels: 3
#         model_channels: 128
#         attention_resolutions: [16, 8]
#         num_res_blocks: 2
#         num_heads: 4

###second try with concat condition
# data:
#   target: main.DataModuleFromConfig
#   params:
#     batch_size: 4
#     num_workers: 8
#     train:
#       target: ldm.data.my_dataset.MyDataset
#       params:
#         # data_root: /g/data/ey6/yiqiao/latent_diffusion/ldm/control_mean
#         data_root: C:/Users/z5495200/Codes/latent-diffusion/ldm/control_mean
#     validation:
#       target: ldm.data.my_dataset.MyDataset
#       params:
#         # data_root: /g/data/ey6/yiqiao/latent_diffusion/ldm/control_mean
#         data_root: C:/Users/z5495200/Codes/latent-diffusion/ldm/control_mean

# lightning:
#   callbacks:
#     image_logger:
#       target: main.ImageLogger
#       params:
#         batch_frequency: 5000
#         max_images: 8
#         increase_log_steps: False
#   trainer:
#     benchmark: True






# model:
#   base_learning_rate: 1.0e-4
#   target: ldm.models.diffusion.ddpm.LatentDiffusion
#   params:
#     first_stage_config:
#       target: ldm.models.autoencoder.AutoencoderKL
#       params:
#         embed_dim: 4
#         ckpt_path: models/first_stage_models/kl-f8/model.ckpt
#         ddconfig:
#           double_z: true
#           z_channels: 4   # 
#           resolution: 256
#           in_channels: 3
#           out_ch: 3
#           ch: 128
#           ch_mult: [1, 2, 4, 4]
#           num_res_blocks: 2
#           attn_resolutions: []
#           dropout: 0.0
#         lossconfig:
#           target: torch.nn.Identity

#     cond_stage_config: "__is_unconditional__"
#     timesteps: 1000
#     loss_type: l2
#     image_size: 256
#     channels: 3
#     linear_start: 0.0001
#     linear_end: 0.02
#     log_every_t: 100
#     l_simple_weight: 1.0
#     conditioning_key: concat
#     clip_denoised: true
#     unet_config:
#       target: ldm.modules.diffusionmodules.openaimodel.UNetModel
#       params:
#         image_size: 256
#         in_channels: 6
#         out_channels: 3
#         model_channels: 128
#         attention_resolutions: [16, 8]
#         num_res_blocks: 2
#         num_heads: 4

model:
  base_learning_rate: 1.0e-4
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        ckpt_path: models/first_stage_models/kl-f8/model.ckpt
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 64
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    cond_stage_config:
      # target: ldm.models.autoencoder.AutoencoderKL  # 使用 Autoencoder 处理 control
      target: ldm.modules.encoders.modules.Identity
      params:
        embed_dim: 4
        ckpt_path: models/first_stage_models/kl-f8/model.ckpt  # 可以是同一个，也可以是 control 专用
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 64
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    timesteps: 200
    loss_type: l2
    image_size: 64
    channels: 3
    linear_start: 0.0001
    linear_end: 0.02
    log_every_t: 100
    l_simple_weight: 1.0
    conditioning_key: crossattn  # 控制条件通过 latent 融合，推荐 crossattn 或 custom latent concat
    clip_denoised: true
    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 8  # latent size after downscaling
        in_channels: 4  # Autoencoder latent dim
        out_channels: 4
        model_channels: 128
        # attention_resolutions: [4, 2, 1]
        attention_resolutions: []
        num_res_blocks: 2
        num_heads: 4

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 8
    # num_workers: 0
    train:
      target: ldm.data.my_dataset.MyDataset
      params:
        # data_root: C:/Users/z5495200/Codes/latent-diffusion/ldm/control_mean
        data_root: /g/data/ey6/yiqiao/latent_diffusion/ldm/control_mean
    validation:
      target: ldm.data.my_dataset.MyDataset
      params:
        # data_root: C:/Users/z5495200/Codes/latent-diffusion/ldm/control_mean
        data_root: /g/data/ey6/yiqiao/latent_diffusion/ldm/control_mean

lightning:
  callbacks:
    image_logger:

    #######Modify stage
      log_images: False
      target: main.ImageLogger
      params:
        batch_frequency: 2000
        max_images: 8
        increase_log_steps: False
  trainer:
    benchmark: True
    max_epochs: 50
